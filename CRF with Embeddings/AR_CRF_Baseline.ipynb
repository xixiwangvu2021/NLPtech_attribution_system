{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eaf003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba623dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sents_from_conll(inputfile):\n",
    "    \n",
    "    rows = csv.reader(open(inputfile, encoding=\"utf-8\"), delimiter='\\t')\n",
    "    sents = []\n",
    "    current_sent = []\n",
    "    for row in rows:\n",
    "        current_sent.append(tuple(row))\n",
    "        #note that this is a simplification that works well for this particular data, in other situations, you may need to do more advanced preprocessing to identify sentence boundaries\n",
    "        if row[0] == \"Sent_end\":\n",
    "            sents.append(current_sent)\n",
    "            current_sent = []\n",
    "    return sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a15a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Word', 'AR_label'), ('The', 'O'), ('Ninth', 'O'), ('Circle', 'O'), (':', 'O'), ('The', 'O'), ('Hellish', 'O'), ('View', 'O'), ('from', 'O'), ('Inside', 'O'), ('the', 'O'), ('Beltway', 'O'), (',', 'O'), ('#', 'O'), ('2', 'O'), ('.', 'O'), ('Sent_end', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sents = extract_sents_from_conll(\"Toy_data_train.tsv\")\n",
    "\n",
    "print(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5c42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2tokens(sent):\n",
    "\n",
    "    return [token for token, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24147d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Word', 'The', 'Ninth', 'Circle', ':', 'The', 'Hellish', 'View', 'from', 'Inside', 'the', 'Beltway', ',', '#', '2', '.', 'Sent_end']\n"
     ]
    }
   ],
   "source": [
    "test =  sent2tokens(sents[0])\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c6e9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "\n",
    "    return [label for token, label  in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c2fac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AR_label', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "test2 = sent2labels(sents[0])\n",
    "\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53fa515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2features(sent, i):\n",
    "    token = sent[i][0]\n",
    "       \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token.lower()\n",
    "    }\n",
    "\n",
    "    if i == 0:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    elif i == len(sent) -1:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10974a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 1.0, 'token': 'word', 'BOS': True}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "features= token2features(sents[0], i=0)\n",
    "\n",
    "print(features)\n",
    "print(type(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21130c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [token2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78f3b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Word', 'AR_label'), ('The', 'O'), ('Ninth', 'O'), ('Circle', 'O'), (':', 'O'), ('The', 'O'), ('Hellish', 'O'), ('View', 'O'), ('from', 'O'), ('Inside', 'O'), ('the', 'O'), ('Beltway', 'O'), (',', 'O'), ('#', 'O'), ('2', 'O'), ('.', 'O'), ('Sent_end', 'O')]\n",
      "[{'bias': 1.0, 'token': 'word', 'BOS': True}, {'bias': 1.0, 'token': 'the'}, {'bias': 1.0, 'token': 'ninth'}, {'bias': 1.0, 'token': 'circle'}, {'bias': 1.0, 'token': ':'}, {'bias': 1.0, 'token': 'the'}, {'bias': 1.0, 'token': 'hellish'}, {'bias': 1.0, 'token': 'view'}, {'bias': 1.0, 'token': 'from'}, {'bias': 1.0, 'token': 'inside'}, {'bias': 1.0, 'token': 'the'}, {'bias': 1.0, 'token': 'beltway'}, {'bias': 1.0, 'token': ','}, {'bias': 1.0, 'token': '#'}, {'bias': 1.0, 'token': '2'}, {'bias': 1.0, 'token': '.'}, {'bias': 1.0, 'token': 'sent_end', 'EOS': True}]\n"
     ]
    }
   ],
   "source": [
    "test1 =sent2features(sents[0])\n",
    "\n",
    "print(sents[0])\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5843afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crf_model(X_train, y_train):\n",
    "\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    return crf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d26163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crf_model(trainingfile):\n",
    "\n",
    "    train_sents = extract_sents_from_conll(trainingfile)\n",
    "    X_train = [sent2features(s) for s in train_sents]\n",
    "    y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "    crf = train_crf_model(X_train, y_train)\n",
    "    \n",
    "    return crf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dba1cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_crf_model(crf, evaluationfile):\n",
    "\n",
    "    test_sents = extract_sents_from_conll(evaluationfile)\n",
    "    X_test = [sent2features(s) for s in test_sents]\n",
    "    y_test = [sent2labels(s) for s in test_sents]\n",
    "    y_pred = crf.predict(X_test)\n",
    "    \n",
    "    return y_pred, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22f5ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_evaluation(eval_data, pred_labels, outputfile):\n",
    "\n",
    "    outfile = open(outputfile, 'w', encoding=\"utf-8\")\n",
    "    \n",
    "    for evalsents, predsents in zip(eval_data, pred_labels):\n",
    "        for data, pred in zip(evalsents, predsents):\n",
    "            token = str(data.get('token'))\n",
    "            outfile.write(token + \"\\t\" + pred + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1e3ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate_crf_model(trainingfile, evaluationfile, outputfile):\n",
    "\n",
    "    '''Perform the full training at once'''\n",
    "    crf = create_crf_model(trainingfile)\n",
    "    labels = list(crf.classes_)\n",
    "    labels.remove('O')\n",
    "    labels.remove('AR_label')\n",
    "    labels\n",
    "    y_pred, X_test, y_test = run_crf_model(crf, evaluationfile)\n",
    "    write_out_evaluation(X_test, y_pred, outputfile)\n",
    "    print('The predictions are written on the output file.')\n",
    "    print(metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=4))\n",
    "    print('Accuracy score for sequence items')\n",
    "    print(metrics.flat_accuracy_score(y_test, y_pred))\n",
    "    print('Precision score for sequence items')\n",
    "    print(metrics.flat_precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall score for sequence items')\n",
    "    print(metrics.flat_recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('F1 score score for sequence items')\n",
    "    print(metrics.flat_f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a6ecd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingfile = \"polnear_withBIO_train.tsv\"\n",
    "evaluationfile = \"polnear_withBIO_dev.tsv\"\n",
    "outputfile = \"polnear_output_CRF_baseline.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51a38b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are written on the output file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['B-SOURCE', 'B-CUE', 'B-CONTENT', 'I-CONTENT', 'I-CUE', 'I-SOURCE'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-SOURCE     0.7425    0.4589    0.5673      1948\n",
      "       B-CUE     0.8055    0.5237    0.6348      2190\n",
      "   B-CONTENT     0.5933    0.3958    0.4748      2193\n",
      "   I-CONTENT     0.7173    0.7389    0.7279     36881\n",
      "       I-CUE     0.4045    0.2096    0.2761      1808\n",
      "    I-SOURCE     0.6111    0.4393    0.5111      4070\n",
      "\n",
      "   micro avg     0.7036    0.6585    0.6803     49090\n",
      "   macro avg     0.6457    0.4611    0.5320     49090\n",
      "weighted avg     0.6964    0.6585    0.6715     49090\n",
      "\n",
      "Accuracy score for sequence items\n",
      "0.6814877471712454\n",
      "Precision score for sequence items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6790784854694446\n",
      "Recall score for sequence items\n",
      "0.6814877471712454\n",
      "F1 score score for sequence items\n",
      "0.6761123604225054\n"
     ]
    }
   ],
   "source": [
    "run_and_evaluate_crf_model(trainingfile, evaluationfile, outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce766860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
