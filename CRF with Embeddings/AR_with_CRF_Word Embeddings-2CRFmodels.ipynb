{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95dae0",
   "metadata": {},
   "source": [
    "# Atribution Relations Extractions Model: \n",
    "## Conditional Random Field (CRF) Approach\n",
    "###  CRF classifier trained with pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1072d4a1",
   "metadata": {},
   "source": [
    "In this notebook, we train and evaluate wto CRF classifiers using 100 dimentional pre-trained GloVe word embeddings as features.\n",
    "\n",
    "The first classifier is trained with only PolNeAR corpus. The second one is trained with both PolNeAr and PARC3 corpus. \n",
    "Note: Nested attributions in PARC3 is not taken into consideration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eaf003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with imports:\n",
    "\n",
    "import sklearn_crfsuite# the model\n",
    "from sklearn_crfsuite import metrics\n",
    "from gensim.models import KeyedVectors # to load pre-trained word embeddings\n",
    "import numpy as np # to create 0 vectors for the words which are not in the vocabulary\n",
    "import pandas as pd # to load input&output files for evaluation\n",
    "import csv # to read the data files for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c69c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-21 14:58:38,116 - glove2word2vec - INFO - running C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\gensim\\scripts\\glove2word2vec.py --input glove.6B.100d.txt --output glove.6B.100d.w2vformat.txt\n",
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\gensim\\scripts\\glove2word2vec.py:125: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  num_lines, num_dims = glove2word2vec(args.input, args.output)\n",
      "2021-06-21 14:58:38,117 - keyedvectors - INFO - loading projection weights from glove.6B.100d.txt\n",
      "2021-06-21 14:59:11,390 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (400000, 100) matrix of type float32 from glove.6B.100d.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2021-06-21T14:59:11.390650', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'load_word2vec_format'}\n",
      "2021-06-21 14:59:11,390 - glove2word2vec - INFO - converting 400000 vectors from glove.6B.100d.txt to glove.6B.100d.w2vformat.txt\n",
      "2021-06-21 14:59:11,937 - keyedvectors - INFO - storing 400000x100 projection weights into glove.6B.100d.w2vformat.txt\n",
      "2021-06-21 14:59:38,909 - glove2word2vec - INFO - Converted model with 400000 vectors and 100 dimensions\n"
     ]
    }
   ],
   "source": [
    "# load the pre-trained word embeddings\n",
    "glove_dimensions = 100\n",
    "!python -m gensim.scripts.glove2word2vec --input  glove.6B.100d.txt --output glove.6B.100d.w2vformat.txt\n",
    "model = KeyedVectors.load_word2vec_format(\"glove.6B.100d.w2vformat.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b897d6",
   "metadata": {},
   "source": [
    "### Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba623dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sents_from_conll(inputfile):\n",
    "    '''Read the data from tsv file, return sentences as tokens with corresponding labels.'''\n",
    "    \n",
    "    rows = csv.reader(open(inputfile, encoding=\"utf-8\"), delimiter='\\t')\n",
    "    sents = []\n",
    "    current_sent = []\n",
    "    for row in rows:\n",
    "        current_sent.append(tuple(row))  \n",
    "        #After each sentence there is a special token: Sent_end. Its label is O. It was added in the preprocessing step.\n",
    "        if row[0] == \"Sent_end\":\n",
    "            sents.append(current_sent)\n",
    "            current_sent = []\n",
    "    return sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a15a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sents = extract_sents_from_conll(\"Toy_data_train.tsv\")\n",
    "\n",
    "#print(sents[0])\n",
    "#print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5c42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2tokens(sent):\n",
    "    '''Take the sentence as token-label pair, return only tokens'''\n",
    "\n",
    "    return [token for token, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24147d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test =  sent2tokens(sents[0])\n",
    "\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6e9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):    \n",
    "    '''Take the sentence as token-label pair, return only labels'''\n",
    "\n",
    "    return [label for token, label  in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2fac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2 = sent2labels(sents[0])\n",
    "\n",
    "#print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7e17e1",
   "metadata": {},
   "source": [
    "It is time to extract the features: \n",
    "\n",
    "IMPORTANT: Crfsuite does not support array features, like word embeddings. Instead, we pass every vector component as a feature.\n",
    "\n",
    "https://stackoverflow.com/questions/58736548/how-to-use-word-embedding-as-features-for-crf-sklearn-crfsuite-model-training\n",
    "https://github.com/scrapinghub/python-crfsuite/issues/39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36555f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding function \n",
    "def get_features(token):\n",
    "    '''Get token, return word vector'''\n",
    "    \n",
    "    token=token.lower()\n",
    "    try:\n",
    "         vector=model[token]\n",
    "    except:\n",
    "        # if the word is not in vocabulary,\n",
    "        # returns zeros array\n",
    "        vector=np.zeros(100,)\n",
    "\n",
    "    return vector   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b90d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector = get_features(\"are\")\n",
    "#print(len(vector))\n",
    "#print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53fa515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2features(sent, i):\n",
    "    '''Get tokens in the sentence, add bias, token and word embeddings as features and return all as a feature dictionary.'''\n",
    "    \n",
    "    token = sent[i][0]\n",
    "    wordembdding=get_features(token)   ## word embedding vector \n",
    "    wordembdding=np.array(wordembdding) ## vectors \n",
    "    \n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token.lower()\n",
    "    }\n",
    "    \n",
    "    for iv,value in enumerate(wordembdding):\n",
    "        features['v{}'.format(iv)]=value\n",
    "\n",
    "    if i == 0:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    elif i == len(sent) -1:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10974a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features= token2features(sents[0], i=0)\n",
    "\n",
    "#print(features)\n",
    "#print(type(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21130c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    '''Get sentence as an input, add the features and return as a list of dictionaries.'''\n",
    "    return [token2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f3b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test3 =sent2features(sents[0])\n",
    "\n",
    "#print(sents[0])\n",
    "#print(type(test3))\n",
    "#print(test3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5843afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crf_model1(X_train, y_train):\n",
    "    '''Compile and fit the model with Gradient descent using the L-BFGS method'''\n",
    "\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    return crf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1742341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crf_model2(X_train, y_train):\n",
    "    '''Compile and fit the model with - Stochastic Gradient Descent with L2 regularization term'''\n",
    "\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='l2sgd',\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    return crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d26163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crf_model(trainingfile, model_no = 1):\n",
    "    \n",
    "    '''Perform the training with the data, return the classifier'''\n",
    "\n",
    "    train_sents = extract_sents_from_conll(trainingfile)\n",
    "    X_train = [sent2features(s) for s in train_sents]\n",
    "    y_train = [sent2labels(s) for s in train_sents]\n",
    "    \n",
    "    if model_no == 2:\n",
    "        crf = train_crf_model2(X_train, y_train)\n",
    "    else:\n",
    "        crf = train_crf_model1(X_train, y_train)\n",
    "    \n",
    "    return crf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dba1cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_crf_model(crf, evaluationfile):\n",
    "    \n",
    "    '''Get and prepare the validation sentences, run the classifier and return predictions'''\n",
    "\n",
    "    test_sents = extract_sents_from_conll(evaluationfile)\n",
    "    X_test = [sent2features(s) for s in test_sents]\n",
    "    y_test = [sent2labels(s) for s in test_sents]\n",
    "    y_pred = crf.predict(X_test)\n",
    "    \n",
    "    return y_pred, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22f5ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_evaluation(eval_data, pred_labels, outputfile):\n",
    "    \n",
    "    '''Write the predicitons to a new file along with tokens'''\n",
    "\n",
    "    outfile = open(outputfile, 'w', encoding=\"utf-8\")\n",
    "    \n",
    "    for evalsents, predsents in zip(eval_data, pred_labels):\n",
    "        for data, pred in zip(evalsents, predsents):\n",
    "            token = str(data.get('token'))\n",
    "            outfile.write(token + \"\\t\" + pred + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d811201",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb67ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate_crf_model(trainingfile, evaluationfile, outputfile, model_no=1):\n",
    "\n",
    "    '''Perform the full training at once'''\n",
    "    crf = create_crf_model(trainingfile, model_no)\n",
    "    labels = list(crf.classes_)\n",
    "    labels.remove('O')\n",
    "    labels.remove('AR_label')\n",
    "    labels\n",
    "    y_pred, X_test, y_test = run_crf_model(crf, evaluationfile)\n",
    "    write_out_evaluation(X_test, y_pred, outputfile)\n",
    "    print('The predictions are written on the output file.')\n",
    "    print(metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=4))\n",
    "    print('Accuracy score for sequence items')\n",
    "    print(metrics.flat_accuracy_score(y_test, y_pred))\n",
    "    print('Precision score for sequence items')\n",
    "    print(metrics.flat_precision_score(y_test, y_pred, average='weighted'))\n",
    "    print('Recall score for sequence items')\n",
    "    print(metrics.flat_recall_score(y_test, y_pred, average='weighted'))\n",
    "    print('F1 score score for sequence items')\n",
    "    print(metrics.flat_f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bca993",
   "metadata": {},
   "source": [
    "## Toy example to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13387e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_trainingfile = \"Toy_data_train.tsv\"\n",
    "toy_evaluationfile = \"Toy_data_eval.tsv\"\n",
    "toy_outputfile = \"toy_output_CRF_Embeddings.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bee3507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are written on the output file.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-SOURCE     0.0000    0.0000    0.0000         2\n",
      "       B-CUE     0.0000    0.0000    0.0000         2\n",
      "   B-CONTENT     0.0000    0.0000    0.0000         2\n",
      "   I-CONTENT     0.7912    1.0000    0.8834        72\n",
      "       I-CUE     0.0000    0.0000    0.0000         1\n",
      "    I-SOURCE     0.0000    0.0000    0.0000         4\n",
      "\n",
      "   micro avg     0.7912    0.8675    0.8276        83\n",
      "   macro avg     0.1319    0.1667    0.1472        83\n",
      "weighted avg     0.6863    0.8675    0.7664        83\n",
      "\n",
      "Accuracy score for sequence items\n",
      "0.8113207547169812\n",
      "Precision score for sequence items\n",
      "0.7311355311355311\n",
      "Recall score for sequence items\n",
      "0.8113207547169812\n",
      "F1 score score for sequence items\n",
      "0.7571321755833852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['B-SOURCE', 'B-CUE', 'B-CONTENT', 'I-CONTENT', 'I-CUE', 'I-SOURCE'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_and_evaluate_crf_model(toy_trainingfile, toy_evaluationfile, toy_outputfile, model_no = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f5bdc",
   "metadata": {},
   "source": [
    "## Set the variables and run the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a6ecd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "polnear_trainingfile = \"polnear_withBIO_train.tsv\"\n",
    "polnear_evaluationfile = \"polnear_withBIO_dev.tsv\"\n",
    "polnear_outputfile = \"polnear_output_CRF_Embeddings.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51a38b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are written on the output file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['B-SOURCE', 'B-CUE', 'B-CONTENT', 'I-CONTENT', 'I-CUE', 'I-SOURCE'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-SOURCE     0.7361    0.5026    0.5973      1948\n",
      "       B-CUE     0.7923    0.5416    0.6433      2190\n",
      "   B-CONTENT     0.6034    0.4086    0.4872      2193\n",
      "   I-CONTENT     0.7285    0.7315    0.7300     36881\n",
      "       I-CUE     0.4172    0.2312    0.2975      1808\n",
      "    I-SOURCE     0.5837    0.4754    0.5240      4070\n",
      "\n",
      "   micro avg     0.7094    0.6598    0.6837     49090\n",
      "   macro avg     0.6435    0.4818    0.5466     49090\n",
      "weighted avg     0.7026    0.6598    0.6770     49090\n",
      "\n",
      "Accuracy score for sequence items\n",
      "0.6844544150638079\n",
      "Precision score for sequence items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6827246874575661\n",
      "Recall score for sequence items\n",
      "0.6844544150638079\n",
      "F1 score score for sequence items\n",
      "0.6803711028530718\n"
     ]
    }
   ],
   "source": [
    "#training takes around 1 hr\n",
    "run_and_evaluate_crf_model(polnear_trainingfile, polnear_evaluationfile, polnear_outputfile, model_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b31d4bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are written on the output file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=['B-SOURCE', 'B-CUE', 'B-CONTENT', 'I-CONTENT', 'I-CUE', 'I-SOURCE'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-SOURCE     0.7272    0.5734    0.6412      1948\n",
      "       B-CUE     0.7659    0.5735    0.6559      2190\n",
      "   B-CONTENT     0.4876    0.4656    0.4763      2193\n",
      "   I-CONTENT     0.6516    0.8639    0.7429     36881\n",
      "       I-CUE     0.4356    0.2655    0.3299      1808\n",
      "    I-SOURCE     0.5133    0.6253    0.5638      4070\n",
      "\n",
      "   micro avg     0.6356    0.7798    0.7003     49090\n",
      "   macro avg     0.5969    0.5612    0.5683     49090\n",
      "weighted avg     0.6329    0.7798    0.6930     49090\n",
      "\n",
      "Accuracy score for sequence items\n",
      "0.6670957302048471\n",
      "Precision score for sequence items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6819193202950458\n",
      "Recall score for sequence items\n",
      "0.6670957302048471\n",
      "F1 score score for sequence items\n",
      "0.6557892185319807\n"
     ]
    }
   ],
   "source": [
    "#training takes around ? hr\n",
    "run_and_evaluate_crf_model(polnear_trainingfile, polnear_evaluationfile, polnear_outputfile, model_no=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb40c5c",
   "metadata": {},
   "source": [
    "End of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170233a9",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032d89e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
