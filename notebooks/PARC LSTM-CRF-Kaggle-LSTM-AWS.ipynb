{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook\n",
    "https://www.kaggle.com/williamroe/bi-lstm-with-crf-for-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.4.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (2.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.12)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.12.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (0.35.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (3.15.8)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.32.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (2.4.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (2.10.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (0.3.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.4.0) (0.12.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.31.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.25.11)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.4.0  # 2.5.0  # 2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons==0.13.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow_addons==0.13.0) (2.12.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install tensorflow_addons==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-crf==0.2.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: seqeval in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras-crf==0.2.0) (1.2.2)\n",
      "Requirement already satisfied: tensorflow in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras-crf==0.2.0) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-addons in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras-crf==0.2.0) (0.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from seqeval->keras-crf==0.2.0) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from seqeval->keras-crf==0.2.0) (1.19.5)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (2.4.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (3.15.8)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (0.35.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (0.12.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.32.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (0.3.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-crf==0.2.0) (1.12)\n",
      "Requirement already satisfied: typeguard>=2.7 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-addons->keras-crf==0.2.0) (2.12.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->keras-crf==0.2.0) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->keras-crf==0.2.0) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->keras-crf==0.2.0) (2.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (1.31.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->keras-crf==0.2.0) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install keras-crf==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-cpu==2.4.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (2.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.1.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (2.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (2.5.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (0.12.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.32.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (2.4.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (3.15.8)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-cpu==2.4.0) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (1.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow-cpu==2.4.0) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-cpu==2.4.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-cpu==2.4.0) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-cpu==2.4.0) (4.7.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-cpu==2.4.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-cpu==2.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-cpu==2.4.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-cpu==2.4.0) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-cpu==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-cpu==2.4.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-cpu==2.4.0) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install tensorflow-cpu==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /private/var/folders/jc/x4s6x68n7rl6xv2nd9v3m96h0000gn/T/pip-req-build-zcylokto\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages\n",
      "Collecting keras\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from keras->keras-contrib==2.0.8) (5.3.1)\n",
      "Requirement already satisfied: six in /Users/bettyvandongen/opt/anaconda3/lib/python3.8/site-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101064 sha256=318c089c66b6f495e2b59edf15fdb616bcb28e967be892985028638c4418a5c4\n",
      "  Stored in directory: /private/var/folders/jc/x4s6x68n7rl6xv2nd9v3m96h0000gn/T/pip-ephem-wheel-cache-prtzwcgk/wheels/67/d2/f4/96ae3c3c62d1e05abfc8860ad0c1207794726d44ebbbb547f3\n",
      "Successfully built keras-contrib\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "# # %pip install keras-contrib==0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/xuxingya/tf2crf\n",
    "# %pip install tf2crf==0.1.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall --yes tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 's3://sagemaker-studio-528576943967-ssf9zkrg3os/parc30-conll/prepared/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import s3fs\n",
    "\n",
    "\n",
    "train_filename = 'parc30_preprocessed_train_noBIO.tsv'\n",
    "df_train = pd.read_csv(filepath + filename, sep=\"\\t\")\n",
    "\n",
    "print(len(df_train.index))\n",
    "df.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11123\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd \n",
    "# import s3fs\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# files_list = listdir(filepath)\n",
    "# # files_list = ['wsj_0003.xml.conll.features.foreval']\n",
    "\n",
    "# df_train = pd.DataFrame()\n",
    "# for filename in files_list[0:100]:\n",
    "#     df = pd.read_csv(filepath + filename, sep=\"\\t\", header=None, engine='python', names=['col' + str(x) for x in range(1, 30) ])\n",
    "#     # Delete all columns fully filled with NaN\n",
    "#     df = df.dropna(axis=1, how='all')\n",
    "#     df_train = df_train.append(df)\n",
    "    \n",
    "# print(len(df_train.index))\n",
    "# # print(sorted(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.n_sent = 1\n",
    "        self.dataset = dataset\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n",
    "                                                        s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', 'CONTENT'), ('September', 'CONTENT'), ('be', 'CONTENT'), ('one', 'CONTENT'), ('of', 'CONTENT'), ('the', 'CONTENT'), ('biggest', 'CONTENT'), ('order', 'CONTENT'), ('month', 'CONTENT'), ('in', 'CONTENT'), ('we', 'CONTENT'), ('history', 'CONTENT'), (',', 'CONTENT'), (\"''\", 'CONTENT'), ('say', 'CUE'), ('James', 'SOURCE'), ('R.', 'SOURCE'), ('Roberts', 'SOURCE'), (',', 'SOURCE'), ('vice', 'SOURCE'), ('president', 'SOURCE'), (',', 'SOURCE'), ('world-wide', 'SOURCE'), ('sale', 'SOURCE'), ('and', 'SOURCE'), ('marketing', 'SOURCE'), (',', 'SOURCE'), ('for', 'SOURCE'), ('Giddings', 'SOURCE'), ('&amp;', 'SOURCE'), ('Lewis', 'SOURCE'), ('Inc.', 'SOURCE'), (',', 'SOURCE'), ('Fond', 'SOURCE'), ('du', 'SOURCE'), ('Lac', 'SOURCE'), (',', 'SOURCE'), ('Wis', 'SOURCE'), ('.', 'O'), ('in', 'O'), ('1979', 'O'), (',', 'O'), ('two', 'O'), ('Voyager', 'O'), ('spacecraft', 'O'), ('send', 'O'), ('back', 'O'), ('stunning', 'O'), ('photo', 'O'), ('of', 'O'), ('jovian', 'O'), ('moon', 'O'), ('Io', 'O'), ('and', 'O'), ('Europa', 'O'), ('that', 'O'), ('show', 'O'), ('they', 'O'), ('to', 'O'), ('be', 'O'), ('among', 'O'), ('the', 'O'), ('most', 'O'), ('intriguing', 'O'), ('body', 'O'), ('in', 'O'), ('the', 'O'), ('solar', 'O'), ('system', 'O'), ('.', 'O'), ('market', 'SOURCE'), ('source', 'SOURCE'), ('say', 'CUE'), ('Reliance', 'CONTENT'), ('have', 'CONTENT'), ('already', 'CONTENT'), ('sell', 'CONTENT'), ('its', 'CONTENT'), ('entire', 'CONTENT'), ('UAL', 'CONTENT'), ('stake', 'CONTENT'), (',', 'CONTENT'), ('and', 'CONTENT'), ('thus', 'CONTENT'), ('would', 'CONTENT'), ('not', 'CONTENT'), ('have', 'CONTENT'), ('any', 'CONTENT'), ('reason', 'CONTENT'), ('to', 'CONTENT'), ('file', 'CONTENT'), ('the', 'CONTENT'), ('application', 'CONTENT'), ('simply', 'CONTENT'), ('to', 'CONTENT'), ('boost', 'CONTENT'), ('the', 'CONTENT'), ('value', 'CONTENT'), ('of', 'CONTENT'), ('its', 'CONTENT'), ('stock', 'CONTENT'), ('.', 'O'), ('on', 'CONTENT'), ('Tuesday', 'CONTENT'), ('afternoon', 'CONTENT'), (',', 'CONTENT'), ('Kemper', 'CONTENT'), ('tell', 'CONTENT'), ('Bear', 'CONTENT'), (',', 'CONTENT'), ('Stearns', 'CONTENT'), ('&amp;', 'CONTENT'), ('Co.', 'CONTENT'), (',', 'CONTENT'), ('General', 'CONTENT'), ('Electric', 'CONTENT'), ('Co.', 'CONTENT'), (\"'s\", 'CONTENT'), ('Kidder', 'CONTENT'), (',', 'CONTENT'), ('Peabody', 'CONTENT'), ('&amp;', 'CONTENT'), ('Co.', 'CONTENT'), ('unit', 'CONTENT'), (',', 'CONTENT'), ('Morgan', 'CONTENT'), ('Stanley', 'CONTENT'), ('and', 'CONTENT'), ('Oppenheimer', 'CONTENT'), ('&amp;', 'CONTENT'), ('Co.', 'CONTENT'), ('that', 'CONTENT'), ('it', 'CONTENT'), ('will', 'CONTENT'), ('no', 'CONTENT'), ('longer', 'CONTENT'), ('do', 'CONTENT'), ('business', 'CONTENT'), ('with', 'CONTENT'), ('they', 'CONTENT'), ('because', 'CONTENT'), ('of', 'CONTENT'), ('they', 'CONTENT'), ('commitment', 'CONTENT'), ('to', 'CONTENT'), ('index', 'CONTENT'), ('arbitrage', 'CONTENT'), (',', 'O'), ('official', 'SOURCE'), ('inside', 'SOURCE'), ('and', 'SOURCE'), ('outside', 'SOURCE'), ('these', 'SOURCE'), ('firm', 'SOURCE'), ('confirm', 'CUE'), ('.', 'O'), ('we', 'CONTENT'), ('expect', 'CONTENT'), ('a', 'CONTENT'), ('choppy', 'CONTENT'), ('and', 'CONTENT'), ('sloppy', 'CONTENT'), ('market', 'CONTENT'), ('for', 'CONTENT'), ('a', 'CONTENT'), ('short', 'CONTENT'), ('period', 'CONTENT'), (',', 'CONTENT'), ('but', 'CONTENT'), ('we', 'CONTENT'), ('do', 'CONTENT'), ('not', 'CONTENT'), ('think', 'CONTENT'), ('it', 'CONTENT'), ('will', 'CONTENT'), ('be', 'CONTENT'), ('ugly', 'CONTENT'), ('.', 'CONTENT'), ('in', 'O'), ('New', 'O'), ('York', 'O'), ('Stock', 'O'), ('Exchange', 'O'), ('composite', 'O'), ('trading', 'O'), (',', 'O'), ('Corning', 'O'), ('close', 'O'), ('at', 'O'), ('$', 'O'), ('38.50', 'O'), (',', 'O'), ('down', 'O'), ('75', 'O'), ('cent', 'O'), ('.', 'O'), ('the', 'SOURCE'), ('department', 'SOURCE'), ('also', 'CUE'), ('say', 'CUE'), ('it', 'CONTENT'), ('take', 'CONTENT'), ('four', 'CONTENT'), ('month', 'CONTENT'), ('to', 'CONTENT'), ('establish', 'CONTENT'), ('a', 'CONTENT'), ('trend', 'CONTENT'), ('.', 'O'), ('skiing', 'O'), (',', 'O'), ('after', 'O'), ('all', 'O'), (',', 'O'), ('have', 'O'), ('mainly', 'O'), ('be', 'O'), ('for', 'O'), ('the', 'O'), ('young', 'O'), ('and', 'O'), ('daring', 'O'), ('and', 'O'), ('many', 'O'), ('baby', 'O'), ('boomer', 'O'), ('have', 'O'), ('outgrow', 'O'), ('skiing', 'O'), ('or', 'O'), ('have', 'O'), ('too', 'O'), ('many', 'O'), ('family', 'O'), ('responsibility', 'O'), ('to', 'O'), ('stick', 'O'), ('with', 'O'), ('the', 'O'), ('sport', 'O'), ('.', 'O'), ('some', 'SOURCE'), ('trader', 'SOURCE'), ('point', 'CUE'), ('out', 'CUE'), ('that', 'CONTENT'), ('as', 'CONTENT'), ('the', 'CONTENT'), ('big', 'CONTENT'), ('brokerage', 'CONTENT'), ('firm', 'CONTENT'), ('back', 'CONTENT'), ('out', 'CONTENT'), ('of', 'CONTENT'), ('program', 'CONTENT'), ('trading', 'CONTENT'), ('for', 'CONTENT'), ('they', 'CONTENT'), ('own', 'CONTENT'), ('account', 'CONTENT'), ('or', 'CONTENT'), ('for', 'CONTENT'), ('client', 'CONTENT'), (',', 'CONTENT'), ('opportunity', 'CONTENT'), ('increase', 'CONTENT'), ('for', 'CONTENT'), ('other', 'CONTENT'), ('to', 'CONTENT'), ('engage', 'CONTENT'), ('in', 'CONTENT'), ('the', 'CONTENT'), ('controversial', 'CONTENT'), ('practice', 'CONTENT'), ('.', 'O'), ('on', 'O'), ('similarity', 'O'), ('between', 'O'), ('China', 'O'), ('and', 'O'), ('the', 'O'), ('Soviet', 'O'), ('Union', 'O'), (':', 'CUE'), ('``', 'CONTENT'), ('in', 'CONTENT'), ('important', 'CONTENT'), ('particulars', 'CONTENT'), (',', 'CONTENT'), ('the', 'CONTENT'), ('soviet', 'CONTENT'), ('be', 'CONTENT'), ('different', 'CONTENT'), ('from', 'CONTENT'), ('the', 'CONTENT'), ('Chinese', 'CONTENT'), ('.', 'CONTENT'), ('but', 'O'), ('some', 'SOURCE'), ('industry', 'SOURCE'), ('executive', 'SOURCE'), ('say', 'CUE'), ('ABC', 'CONTENT'), (',', 'CONTENT'), ('in', 'CONTENT'), ('anticipation', 'CONTENT'), ('of', 'CONTENT'), ('a', 'CONTENT'), ('four-game', 'CONTENT'), ('sweep', 'CONTENT'), (',', 'CONTENT'), ('limit', 'CONTENT'), ('its', 'CONTENT'), ('loss', 'CONTENT'), ('by', 'CONTENT'), ('jack', 'CONTENT'), ('up', 'CONTENT'), ('the', 'CONTENT'), ('number', 'CONTENT'), ('of', 'CONTENT'), ('commercial', 'CONTENT'), ('it', 'CONTENT'), ('air', 'CONTENT'), ('in', 'CONTENT'), ('the', 'CONTENT'), ('third', 'CONTENT'), ('and', 'CONTENT'), ('fourth', 'CONTENT'), ('game', 'CONTENT'), ('.', 'O'), ('it', 'O'), ('have', 'O'), ('reopen', 'O'), ('the', 'O'), ('bitter', 'O'), ('wrangling', 'O'), ('between', 'O'), ('the', 'O'), ('White', 'O'), ('House', 'O'), ('and', 'O'), ('Congress', 'O'), ('over', 'O'), ('who', 'O'), ('be', 'O'), ('responsible', 'O'), ('for', 'O'), ('the', 'O'), ('failure', 'O'), ('to', 'O'), ('oust', 'O'), ('Mr.', 'O'), ('Noriega', 'O'), ('and', 'O'), (',', 'O'), ('more', 'O'), ('broadly', 'O'), (',', 'O'), ('for', 'O'), ('difficulty', 'O'), ('in', 'O'), ('carry', 'O'), ('out', 'O'), ('covert', 'O'), ('activity', 'O'), ('abroad', 'O'), ('.', 'O'), ('aide', 'SOURCE'), ('both', 'SOURCE'), ('in', 'SOURCE'), ('the', 'SOURCE'), ('House', 'SOURCE'), ('and', 'SOURCE'), ('Senate', 'SOURCE'), ('say', 'CUE'), ('the', 'CONTENT'), ('withdrawal', 'CONTENT'), ('of', 'CONTENT'), ('the', 'CONTENT'), ('Trump', 'CONTENT'), ('bid', 'CONTENT'), ('for', 'CONTENT'), ('AMR', 'CONTENT'), ('be', 'CONTENT'), ('not', 'CONTENT'), ('likely', 'CONTENT'), ('to', 'CONTENT'), ('deflate', 'CONTENT'), ('effort', 'CONTENT'), ('to', 'CONTENT'), ('push', 'CONTENT'), ('the', 'CONTENT'), ('legislation', 'CONTENT'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 560\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "print ('Maximum sequence length:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how long sentences are so that we can pad them\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(dataset[\"word\"].values))\n",
    "words.append(\"ENDPAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2364"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = len(words)\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'CONTENT', 'SOURCE', 'CUE']\n"
     ]
    }
   ],
   "source": [
    "from math import nan\n",
    "\n",
    "tags = []\n",
    "for tag in set(dataset[\"tag\"].values):\n",
    "    if tag is nan or isinstance(tag, float):\n",
    "        tags.append('unk')\n",
    "    else:\n",
    "        tags.append(tag)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "idx2tag = {v: k for k, v in iteritems(tag2idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2069"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'CONTENT': 1, 'SOURCE': 2, 'CUE': 3}\n"
     ]
    }
   ],
   "source": [
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CUE'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O', 1: 'CONTENT', 2: 'SOURCE', 3: 'CUE'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2340, 1215, 1947, 2360, 1040, 2069, 313, 293, 1167, 1253, 1571, 1872, 165, 297, 173, 2147, 722, 1765, 165, 1476, 509, 165, 1573, 1694, 2018, 204, 165, 2202, 1422, 2322, 1590, 1581, 165, 1950, 1132, 2005, 165, 715, 1161, 1253, 1307, 165, 2072, 2167, 2270, 1715, 2162, 812, 1912, 1040, 1552, 1235, 2272, 2018, 230, 467, 2304, 2016, 794, 1947, 775, 2069, 1892, 1708, 2342, 1253, 2069, 1297, 1056, 1161, 887, 1601, 173, 687, 430, 2295, 674, 1591, 366, 278, 423, 165, 2018, 1089, 214, 2206, 430, 865, 45, 794, 2294, 2069, 484, 1544, 794, 763, 2069, 222, 1040, 1591, 89, 1161, 604, 1898, 837, 165, 2075, 587, 380, 165, 2145, 2322, 1177, 165, 1128, 1894, 1177, 2225, 2157, 165, 1906, 2322, 1177, 1880, 165, 1053, 2076, 2018, 1843, 2322, 1177, 467, 1357, 81, 2127, 1630, 653, 1411, 768, 2016, 314, 1040, 2016, 2358, 794, 97, 1706, 165, 445, 188, 2018, 647, 1945, 2166, 1027, 1161, 1571, 507, 823, 220, 2018, 1354, 887, 2202, 823, 395, 1103, 165, 654, 1571, 653, 2206, 702, 1357, 81, 1947, 591, 1161, 1253, 2121, 2165, 1636, 729, 1585, 54, 165, 2031, 1576, 1462, 596, 1699, 165, 346, 1705, 1741, 1161, 2069, 1443, 1118, 173, 1357, 1191, 1007, 1167, 794, 1319, 823, 548, 1161, 915, 165, 2245, 676, 165, 430, 1818, 1947, 2202, 2069, 1026, 2018, 1424, 2018, 969, 1802, 1361, 430, 1740, 915, 236, 430, 1035, 969, 1111, 1707, 794, 1638, 768, 2069, 575, 1161, 709, 892, 1836, 1048, 467, 1649, 2069, 466, 2344, 2166, 2162, 1048, 1040, 20, 54, 2202, 2016, 1136, 719, 236, 2202, 462, 165, 1565, 442, 2202, 1301, 794, 2099, 1253, 2069, 1418, 1196, 1161, 604, 772, 1518, 276, 2018, 2069, 2352, 1750, 2164, 2340, 1253, 1348, 2315, 165, 2069, 1983, 1947, 749, 2170, 2069, 170, 1161, 654, 709, 336, 1702, 173, 1941, 165, 1253, 433, 1040, 823, 486, 1614, 165, 1713, 1591, 1972, 1172, 1138, 707, 2069, 688, 1040, 1265, 1357, 71, 1253, 2069, 2201, 2018, 1617, 935, 1161, 1357, 430, 354, 2069, 391, 1909, 1518, 2069, 929, 1506, 2018, 1376, 1151, 257, 1947, 1094, 2202, 2069, 1046, 794, 2054, 1248, 1854, 2018, 165, 2187, 625, 165, 2202, 1350, 1253, 1402, 1048, 933, 1640, 1092, 1161, 1724, 1110, 1253, 2069, 1506, 2018, 14, 173, 2069, 626, 1040, 2069, 1777, 735, 2202, 157, 1947, 2206, 930, 794, 2345, 46, 794, 1174, 2069, 1662, 1161]\n"
     ]
    }
   ],
   "source": [
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-9087bc21783f>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.array(X).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2340 1215 1947 2360 1040 2069  313  293 1167 1253 1571 1872  165  297\n",
      "  173 2147  722 1765  165 1476  509  165 1573 1694 2018  204  165 2202\n",
      " 1422 2322 1590 1581  165 1950 1132 2005  165  715 1161 1253 1307  165\n",
      " 2072 2167 2270 1715 2162  812 1912 1040 1552 1235 2272 2018  230  467\n",
      " 2304 2016  794 1947  775 2069 1892 1708 2342 1253 2069 1297 1056 1161\n",
      "  887 1601  173  687  430 2295  674 1591  366  278  423  165 2018 1089\n",
      "  214 2206  430  865   45  794 2294 2069  484 1544  794  763 2069  222\n",
      " 1040 1591   89 1161  604 1898  837  165 2075  587  380  165 2145 2322\n",
      " 1177  165 1128 1894 1177 2225 2157  165 1906 2322 1177 1880  165 1053\n",
      " 2076 2018 1843 2322 1177  467 1357   81 2127 1630  653 1411  768 2016\n",
      "  314 1040 2016 2358  794   97 1706  165  445  188 2018  647 1945 2166\n",
      " 1027 1161 1571  507  823  220 2018 1354  887 2202  823  395 1103  165\n",
      "  654 1571  653 2206  702 1357   81 1947  591 1161 1253 2121 2165 1636\n",
      "  729 1585   54  165 2031 1576 1462  596 1699  165  346 1705 1741 1161\n",
      " 2069 1443 1118  173 1357 1191 1007 1167  794 1319  823  548 1161  915\n",
      "  165 2245  676  165  430 1818 1947 2202 2069 1026 2018 1424 2018  969\n",
      " 1802 1361  430 1740  915  236  430 1035  969 1111 1707  794 1638  768\n",
      " 2069  575 1161  709  892 1836 1048  467 1649 2069  466 2344 2166 2162\n",
      " 1048 1040   20   54 2202 2016 1136  719  236 2202  462  165 1565  442\n",
      " 2202 1301  794 2099 1253 2069 1418 1196 1161  604  772 1518  276 2018\n",
      " 2069 2352 1750 2164 2340 1253 1348 2315  165 2069 1983 1947  749 2170\n",
      " 2069  170 1161  654  709  336 1702  173 1941  165 1253  433 1040  823\n",
      "  486 1614  165 1713 1591 1972 1172 1138  707 2069  688 1040 1265 1357\n",
      "   71 1253 2069 2201 2018 1617  935 1161 1357  430  354 2069  391 1909\n",
      " 1518 2069  929 1506 2018 1376 1151  257 1947 1094 2202 2069 1046  794\n",
      " 2054 1248 1854 2018  165 2187  625  165 2202 1350 1253 1402 1048  933\n",
      " 1640 1092 1161 1724 1110 1253 2069 1506 2018   14  173 2069  626 1040\n",
      " 2069 1777  735 2202  157 1947 2206  930  794 2345   46  794 1174 2069\n",
      " 1662 1161 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363\n",
      " 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363 2363]\n"
     ]
    }
   ],
   "source": [
    "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=n_words - 1)\n",
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences[25]\n",
      "[('shipment', 'O'), ('have', 'O'), ('run', 'O'), ('well', 'O'), ('ahead', 'O'), ('of', 'O'), ('1988', 'O'), ('all', 'O'), ('year', 'O'), (',', 'O'), ('as', 'O'), ('machine', 'O'), ('tool', 'O'), ('builder', 'O'), ('produce', 'O'), ('against', 'O'), ('relatively', 'O'), ('good', 'O'), ('backlog', 'O'), ('.', 'O'), ('they', 'SOURCE'), ('say', 'CUE'), ('they', 'CONTENT'), ('drop', 'CONTENT'), ('plan', 'CONTENT'), ('to', 'CONTENT'), ('infiltrate', 'CONTENT'), ('the', 'CONTENT'), ('Kennedy', 'CONTENT'), ('Space', 'CONTENT'), ('Center', 'CONTENT'), ('after', 'CONTENT'), ('NASA', 'CONTENT'), ('beef', 'CONTENT'), ('up', 'CONTENT'), ('its', 'CONTENT'), ('security', 'CONTENT'), ('.', 'O'), ('Mr.', 'O'), ('Timbers', 'O'), ('counter', 'O'), ('that', 'O'), ('``', 'O'), ('the', 'O'), ('mere', 'O'), ('fact', 'O'), ('they', 'O'), ('put', 'O'), ('in', 'O'), ('circuit', 'O'), ('breaker', 'O'), ('be', 'O'), ('a', 'O'), ('admission', 'O'), ('of', 'O'), ('they', 'O'), ('problem', 'O'), ('.', 'O'), (\"''\", 'O'), ('a', 'O'), ('earnings', 'O'), ('disappointment', 'O'), ('may', 'O'), ('reflect', 'O'), ('a', 'O'), ('situation', 'O'), ('that', 'O'), ('be', 'O'), ('short-term', 'O'), ('.', 'O'), ('September', 'O'), (',', 'O'), ('and', 'O'), ('the', 'O'), ('change', 'O'), ('from', 'O'), ('August', 'O'), (',', 'O'), ('be', 'O'), (':', 'O'), ('from', 'O'), ('1.11', 'O'), ('in', 'O'), ('the', 'O'), ('previous', 'O'), ('month', 'O'), ('.', 'O'), ('for', 'O'), ('$', 'O'), ('15', 'O'), (',', 'O'), ('they', 'O'), ('can', 'O'), ('enjoy', 'O'), ('they', 'O'), ('own', 'O'), ('nightly', 'O'), ('entertainment', 'O'), (',', 'O'), ('with', 'O'), ('dinner', 'O'), (',', 'O'), ('without', 'O'), ('mom', 'O'), ('and', 'O'), ('dad', 'O'), ('.', 'O'), ('bond', 'O'), ('price', 'O'), ('rise', 'O'), ('.', 'O'), ('on', 'O'), ('u.s.-japan', 'O'), ('relation', 'O'), (':', 'CUE'), ('``', 'CONTENT'), ('I', 'CONTENT'), ('be', 'CONTENT'), ('encouraged', 'CONTENT'), ('.', 'CONTENT'), ('one', 'O'), ('senior', 'O'), ('administration', 'O'), ('official', 'O'), ('call', 'O'), ('the', 'O'), ('guideline', 'O'), ('``', 'O'), ('outrageous', 'O'), (\"''\", 'O'), ('and', 'O'), ('say', 'CUE'), ('it', 'CONTENT'), ('could', 'CONTENT'), ('make', 'CONTENT'), ('U.S.', 'CONTENT'), ('operative', 'CONTENT'), ('reluctant', 'CONTENT'), ('to', 'CONTENT'), ('even', 'CONTENT'), ('listen', 'CONTENT'), ('to', 'CONTENT'), ('coup', 'CONTENT'), ('plan', 'CONTENT'), ('for', 'CONTENT'), ('fear', 'CONTENT'), ('they', 'CONTENT'), ('may', 'CONTENT'), ('get', 'CONTENT'), ('into', 'CONTENT'), ('legal', 'CONTENT'), ('trouble', 'CONTENT'), ('.', 'O')]\n",
      "y_idx[25]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "sentences[10]\n",
      "[('``', 'CONTENT'), ('September', 'CONTENT'), ('be', 'CONTENT'), ('one', 'CONTENT'), ('of', 'CONTENT'), ('the', 'CONTENT'), ('biggest', 'CONTENT'), ('order', 'CONTENT'), ('month', 'CONTENT'), ('in', 'CONTENT'), ('we', 'CONTENT'), ('history', 'CONTENT'), (',', 'CONTENT'), (\"''\", 'CONTENT'), ('say', 'CUE'), ('James', 'SOURCE'), ('R.', 'SOURCE'), ('Roberts', 'SOURCE'), (',', 'SOURCE'), ('vice', 'SOURCE'), ('president', 'SOURCE'), (',', 'SOURCE'), ('world-wide', 'SOURCE'), ('sale', 'SOURCE'), ('and', 'SOURCE'), ('marketing', 'SOURCE'), (',', 'SOURCE'), ('for', 'SOURCE'), ('Giddings', 'SOURCE'), ('&amp;', 'SOURCE'), ('Lewis', 'SOURCE'), ('Inc.', 'SOURCE'), (',', 'SOURCE'), ('Fond', 'SOURCE'), ('du', 'SOURCE'), ('Lac', 'SOURCE'), (',', 'SOURCE'), ('Wis', 'SOURCE'), ('.', 'O'), ('in', 'O'), ('1979', 'O'), (',', 'O'), ('two', 'O'), ('Voyager', 'O'), ('spacecraft', 'O'), ('send', 'O'), ('back', 'O'), ('stunning', 'O'), ('photo', 'O'), ('of', 'O'), ('jovian', 'O'), ('moon', 'O'), ('Io', 'O'), ('and', 'O'), ('Europa', 'O'), ('that', 'O'), ('show', 'O'), ('they', 'O'), ('to', 'O'), ('be', 'O'), ('among', 'O'), ('the', 'O'), ('most', 'O'), ('intriguing', 'O'), ('body', 'O'), ('in', 'O'), ('the', 'O'), ('solar', 'O'), ('system', 'O'), ('.', 'O'), ('market', 'SOURCE'), ('source', 'SOURCE'), ('say', 'CUE'), ('Reliance', 'CONTENT'), ('have', 'CONTENT'), ('already', 'CONTENT'), ('sell', 'CONTENT'), ('its', 'CONTENT'), ('entire', 'CONTENT'), ('UAL', 'CONTENT'), ('stake', 'CONTENT'), (',', 'CONTENT'), ('and', 'CONTENT'), ('thus', 'CONTENT'), ('would', 'CONTENT'), ('not', 'CONTENT'), ('have', 'CONTENT'), ('any', 'CONTENT'), ('reason', 'CONTENT'), ('to', 'CONTENT'), ('file', 'CONTENT'), ('the', 'CONTENT'), ('application', 'CONTENT'), ('simply', 'CONTENT'), ('to', 'CONTENT'), ('boost', 'CONTENT'), ('the', 'CONTENT'), ('value', 'CONTENT'), ('of', 'CONTENT'), ('its', 'CONTENT'), ('stock', 'CONTENT'), ('.', 'O'), ('on', 'CONTENT'), ('Tuesday', 'CONTENT'), ('afternoon', 'CONTENT'), (',', 'CONTENT'), ('Kemper', 'CONTENT'), ('tell', 'CONTENT'), ('Bear', 'CONTENT'), (',', 'CONTENT'), ('Stearns', 'CONTENT'), ('&amp;', 'CONTENT'), ('Co.', 'CONTENT'), (',', 'CONTENT'), ('General', 'CONTENT'), ('Electric', 'CONTENT'), ('Co.', 'CONTENT'), (\"'s\", 'CONTENT'), ('Kidder', 'CONTENT'), (',', 'CONTENT'), ('Peabody', 'CONTENT'), ('&amp;', 'CONTENT'), ('Co.', 'CONTENT'), ('unit', 'CONTENT'), (',', 'CONTENT'), ('Morgan', 'CONTENT'), ('Stanley', 'CONTENT'), ('and', 'CONTENT'), ('Oppenheimer', 'CONTENT'), ('&amp;', 'CONTENT'), ('Co.', 'CONTENT'), ('that', 'CONTENT'), ('it', 'CONTENT'), ('will', 'CONTENT'), ('no', 'CONTENT'), ('longer', 'CONTENT'), ('do', 'CONTENT'), ('business', 'CONTENT'), ('with', 'CONTENT'), ('they', 'CONTENT'), ('because', 'CONTENT'), ('of', 'CONTENT'), ('they', 'CONTENT'), ('commitment', 'CONTENT'), ('to', 'CONTENT'), ('index', 'CONTENT'), ('arbitrage', 'CONTENT'), (',', 'O'), ('official', 'SOURCE'), ('inside', 'SOURCE'), ('and', 'SOURCE'), ('outside', 'SOURCE'), ('these', 'SOURCE'), ('firm', 'SOURCE'), ('confirm', 'CUE'), ('.', 'O'), ('we', 'CONTENT'), ('expect', 'CONTENT'), ('a', 'CONTENT'), ('choppy', 'CONTENT'), ('and', 'CONTENT'), ('sloppy', 'CONTENT'), ('market', 'CONTENT'), ('for', 'CONTENT'), ('a', 'CONTENT'), ('short', 'CONTENT'), ('period', 'CONTENT'), (',', 'CONTENT'), ('but', 'CONTENT'), ('we', 'CONTENT'), ('do', 'CONTENT'), ('not', 'CONTENT'), ('think', 'CONTENT'), ('it', 'CONTENT'), ('will', 'CONTENT'), ('be', 'CONTENT'), ('ugly', 'CONTENT'), ('.', 'CONTENT'), ('in', 'O'), ('New', 'O'), ('York', 'O'), ('Stock', 'O'), ('Exchange', 'O'), ('composite', 'O'), ('trading', 'O'), (',', 'O'), ('Corning', 'O'), ('close', 'O'), ('at', 'O'), ('$', 'O'), ('38.50', 'O'), (',', 'O'), ('down', 'O'), ('75', 'O'), ('cent', 'O'), ('.', 'O'), ('the', 'SOURCE'), ('department', 'SOURCE'), ('also', 'CUE'), ('say', 'CUE'), ('it', 'CONTENT'), ('take', 'CONTENT'), ('four', 'CONTENT'), ('month', 'CONTENT'), ('to', 'CONTENT'), ('establish', 'CONTENT'), ('a', 'CONTENT'), ('trend', 'CONTENT'), ('.', 'O'), ('skiing', 'O'), (',', 'O'), ('after', 'O'), ('all', 'O'), (',', 'O'), ('have', 'O'), ('mainly', 'O'), ('be', 'O'), ('for', 'O'), ('the', 'O'), ('young', 'O'), ('and', 'O'), ('daring', 'O'), ('and', 'O'), ('many', 'O'), ('baby', 'O'), ('boomer', 'O'), ('have', 'O'), ('outgrow', 'O'), ('skiing', 'O'), ('or', 'O'), ('have', 'O'), ('too', 'O'), ('many', 'O'), ('family', 'O'), ('responsibility', 'O'), ('to', 'O'), ('stick', 'O'), ('with', 'O'), ('the', 'O'), ('sport', 'O'), ('.', 'O'), ('some', 'SOURCE'), ('trader', 'SOURCE'), ('point', 'CUE'), ('out', 'CUE'), ('that', 'CONTENT'), ('as', 'CONTENT'), ('the', 'CONTENT'), ('big', 'CONTENT'), ('brokerage', 'CONTENT'), ('firm', 'CONTENT'), ('back', 'CONTENT'), ('out', 'CONTENT'), ('of', 'CONTENT'), ('program', 'CONTENT'), ('trading', 'CONTENT'), ('for', 'CONTENT'), ('they', 'CONTENT'), ('own', 'CONTENT'), ('account', 'CONTENT'), ('or', 'CONTENT'), ('for', 'CONTENT'), ('client', 'CONTENT'), (',', 'CONTENT'), ('opportunity', 'CONTENT'), ('increase', 'CONTENT'), ('for', 'CONTENT'), ('other', 'CONTENT'), ('to', 'CONTENT'), ('engage', 'CONTENT'), ('in', 'CONTENT'), ('the', 'CONTENT'), ('controversial', 'CONTENT'), ('practice', 'CONTENT'), ('.', 'O'), ('on', 'O'), ('similarity', 'O'), ('between', 'O'), ('China', 'O'), ('and', 'O'), ('the', 'O'), ('Soviet', 'O'), ('Union', 'O'), (':', 'CUE'), ('``', 'CONTENT'), ('in', 'CONTENT'), ('important', 'CONTENT'), ('particulars', 'CONTENT'), (',', 'CONTENT'), ('the', 'CONTENT'), ('soviet', 'CONTENT'), ('be', 'CONTENT'), ('different', 'CONTENT'), ('from', 'CONTENT'), ('the', 'CONTENT'), ('Chinese', 'CONTENT'), ('.', 'CONTENT'), ('but', 'O'), ('some', 'SOURCE'), ('industry', 'SOURCE'), ('executive', 'SOURCE'), ('say', 'CUE'), ('ABC', 'CONTENT'), (',', 'CONTENT'), ('in', 'CONTENT'), ('anticipation', 'CONTENT'), ('of', 'CONTENT'), ('a', 'CONTENT'), ('four-game', 'CONTENT'), ('sweep', 'CONTENT'), (',', 'CONTENT'), ('limit', 'CONTENT'), ('its', 'CONTENT'), ('loss', 'CONTENT'), ('by', 'CONTENT'), ('jack', 'CONTENT'), ('up', 'CONTENT'), ('the', 'CONTENT'), ('number', 'CONTENT'), ('of', 'CONTENT'), ('commercial', 'CONTENT'), ('it', 'CONTENT'), ('air', 'CONTENT'), ('in', 'CONTENT'), ('the', 'CONTENT'), ('third', 'CONTENT'), ('and', 'CONTENT'), ('fourth', 'CONTENT'), ('game', 'CONTENT'), ('.', 'O'), ('it', 'O'), ('have', 'O'), ('reopen', 'O'), ('the', 'O'), ('bitter', 'O'), ('wrangling', 'O'), ('between', 'O'), ('the', 'O'), ('White', 'O'), ('House', 'O'), ('and', 'O'), ('Congress', 'O'), ('over', 'O'), ('who', 'O'), ('be', 'O'), ('responsible', 'O'), ('for', 'O'), ('the', 'O'), ('failure', 'O'), ('to', 'O'), ('oust', 'O'), ('Mr.', 'O'), ('Noriega', 'O'), ('and', 'O'), (',', 'O'), ('more', 'O'), ('broadly', 'O'), (',', 'O'), ('for', 'O'), ('difficulty', 'O'), ('in', 'O'), ('carry', 'O'), ('out', 'O'), ('covert', 'O'), ('activity', 'O'), ('abroad', 'O'), ('.', 'O'), ('aide', 'SOURCE'), ('both', 'SOURCE'), ('in', 'SOURCE'), ('the', 'SOURCE'), ('House', 'SOURCE'), ('and', 'SOURCE'), ('Senate', 'SOURCE'), ('say', 'CUE'), ('the', 'CONTENT'), ('withdrawal', 'CONTENT'), ('of', 'CONTENT'), ('the', 'CONTENT'), ('Trump', 'CONTENT'), ('bid', 'CONTENT'), ('for', 'CONTENT'), ('AMR', 'CONTENT'), ('be', 'CONTENT'), ('not', 'CONTENT'), ('likely', 'CONTENT'), ('to', 'CONTENT'), ('deflate', 'CONTENT'), ('effort', 'CONTENT'), ('to', 'CONTENT'), ('push', 'CONTENT'), ('the', 'CONTENT'), ('legislation', 'CONTENT'), ('.', 'O')]\n",
      "y_idx[10]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "394\n"
     ]
    }
   ],
   "source": [
    "y_idx = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "print('sentences[25]')\n",
    "print(sentences[25])\n",
    "print('y_idx[25]')\n",
    "print(y_idx[25])\n",
    "print('sentences[10]')\n",
    "print(sentences[10])\n",
    "print('y_idx[10]')\n",
    "print(y_idx[10])\n",
    "print(len(y_idx[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 3 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 2 2 2 2 2 2 3 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 2 2 3 3 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 3 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "y = pad_sequences(maxlen=maxlen, sequences=y_idx, padding=\"post\", value=tag2idx[\"O\"])\n",
    "print(y[10])\n",
    "print(len(y[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "print(y[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "X_train, y_train = X, y\n",
    "X_test, y_test = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "2340\n",
      "[0. 1. 0. 0.]\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[10][0])\n",
    "print(X_test[10][0])\n",
    "print(y_train[10][0])\n",
    "print(y_test[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential  # , Input\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import tensorflow.keras as k\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(k.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.utils as generic_utils\n",
    "# from keras_contrib.layers.crf import CRF\n",
    "# AttributeError: module 'tensorflow.compat.v2' has no attribute '__internal__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/xuxingya/tf2crf\n",
    "\n",
    "More inspiration:\n",
    "https://github.com/Akshayc1/named-entity-recognition/blob/master/NER%20using%20Bidirectional%20LSTM%20-%20CRF%20.ipynb\n",
    "https://www.kaggle.com/nikkisharma536/ner-with-bilstm-and-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle example code \n",
    "\n",
    "inputs = Input(shape=(maxlen,))\n",
    "# https://stackoverflow.com/questions/55770009/how-to-use-a-pre-trained-embedding-matrix-in-tensorflow-2-0-rnn-as-initial-weigh\n",
    "outputs = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(inputs)\n",
    "outputs = Bidirectional(LSTM(units=word_embedding_size, \n",
    "                             return_sequences=True, \n",
    "                             dropout=0.5, \n",
    "                             recurrent_dropout=0.5, \n",
    "                             kernel_initializer=k.initializers.he_normal()))(outputs)\n",
    "outputs = LSTM(units=word_embedding_size * 2, \n",
    "               return_sequences=True, \n",
    "               dropout=0.5, \n",
    "               recurrent_dropout=0.5, \n",
    "               kernel_initializer=k.initializers.he_normal())(outputs)\n",
    "# https://github.com/xuxingya/tf2crf: Add internal kernel like CRF in keras_contrib, so now there is no need to stack a Dense layer before the CRF layer.\n",
    "outputs = Dense(n_tags, activation=\"relu\")(outputs)  # previously softmax output layer\n",
    "# outputs = TimeDistributed(Dense(n_tags, activation=\"relu\"))(outputs)  # previously softmax output layer\n",
    "# outputs = TimeDistributed(Dense(n_tags, activation=tensorflow.keras.activations.softmax))(outputs)  # previously softmax output layer\n",
    "\n",
    "# crf = CRF(n_tags)  # CRF layer\n",
    "# out = crf(outputs)  # output\n",
    "# model = Model(input, out)\n",
    "\n",
    "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle version (removed CRF code)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# https://stackoverflow.com/questions/61742556/valueerror-shapes-none-1-and-none-2-are-incompatible\n",
    "# model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])# Saving the best only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the best only\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# filepath=\"ner-bi-lstm-td-model-{val_accuracy:.2f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tfcrf version\n",
    "# model.fit(x=X_train, y=np.array(y_train), epochs=1, batch_size=2)\n",
    "# model.save('tests/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate generalization metrics\n",
    "# i = len(X_test) - 1 \n",
    "# score = model.evaluate(np.array([X_test[:i]]), y_test, verbose=0)\n",
    "# print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 51s 51s/step - loss: nan - accuracy: 0.5068 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 25s 25s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 22s 22s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 21s 21s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 21s 21s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 21s 21s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 22s 22s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 22s 22s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 23s 23s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 23s 23s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 22s 22s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 21s 21s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 21s 21s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 20s 20s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 19s 19s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 19s 19s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 20s 20s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 19s 19s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 19s 19s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 20s 20s/step - loss: nan - accuracy: 0.8493 - val_loss: nan - val_accuracy: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x178fc5d00>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, np.array(y_train), batch_size=256, epochs=20, validation_split=0.1, verbose=1)  # , callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 560)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 560, 300)          709200    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 560, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 560, 600)          2882400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 560, 4)            2404      \n",
      "=================================================================\n",
      "Total params: 5,036,404\n",
      "Trainable params: 5,036,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = {}\n",
    "TN = {}\n",
    "FP = {}\n",
    "FN = {}\n",
    "for tag in tag2idx.keys():\n",
    "    TP[tag] = 0\n",
    "    TN[tag] = 0    \n",
    "    FP[tag] = 0    \n",
    "    FN[tag] = 0    \n",
    "\n",
    "def accumulate_score_by_tag(gt, pred):\n",
    "    \"\"\"\n",
    "    For each tag keep stats\n",
    "    \"\"\"\n",
    "    if gt == pred:\n",
    "        TP[gt] += 1\n",
    "    elif gt != 'O' and pred == 'O':\n",
    "        FN[gt] +=1\n",
    "    elif gt == 'O' and pred != 'O':\n",
    "        FP[gt] += 1\n",
    "    else:\n",
    "        TN[gt] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1857  541 1947 ...   52 1115 1161]\n",
      " [1215  293 2202 ... 2363 2363 2363]\n",
      " [ 292  161 1219 ... 2363 2363 2363]\n",
      " ...\n",
      " [2069  170 1794 ... 2363 2363 2363]\n",
      " [ 898 1506 1947 ... 2363 2363 2363]\n",
      " [1248  102 1947 ... 2363 2363 2363]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1  # len(X_test) - 1  # Last one \n",
    "# p = model.predict(np.array([X_test[i]]))\n",
    "# p = np.argmax(p, axis=-1)\n",
    "# print(p.shape)\n",
    "# gt = np.argmax(y_test[i], axis=-1)\n",
    "# print(gt)\n",
    "# print(\"{:14}: ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "# print(p)\n",
    "# for idx, (w,pred) in enumerate(zip(X_test[i],p[0])):\n",
    "#     if words[w] == 'ENDPAD':\n",
    "#         break\n",
    "#     print(\"{:14}: ({:5}): {}\".format(words[w],idx2tag[gt[idx]],tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 560, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p, axis=axis)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.86      1.00      0.93     31920\n",
      "     CONTENT       0.00      0.00      0.00      4157\n",
      "      SOURCE       0.00      0.00      0.00       677\n",
      "         CUE       0.00      0.00      0.00       206\n",
      "\n",
      "    accuracy                           0.86     36960\n",
      "   macro avg       0.22      0.25      0.23     36960\n",
      "weighted avg       0.75      0.86      0.80     36960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=axis).ravel(), np.argmax(p, axis=axis).ravel(),labels=list(idx2tag.keys()), target_names=list(idx2tag.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(X_test):\n",
    "    y_hat = np.argmax(p[i], axis=-1)\n",
    "    gt = np.argmax(y_test[i], axis=-1)\n",
    "    for idx, (w,pred) in enumerate(zip(sentence,y_hat)):\n",
    "        accumulate_score_by_tag(idx2tag[gt[idx]],tags[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:O\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:     63840\n",
      "tag:CONTENT\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:      8314\tTP:         0\n",
      "tag:SOURCE\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:      1354\tTP:         0\n",
      "tag:CUE\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:       412\tTP:         0\n"
     ]
    }
   ],
   "source": [
    "for tag in tag2idx.keys():\n",
    "    print(f'tag:{tag}')    \n",
    "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
    "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
